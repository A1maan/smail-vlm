{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch transformers pillow"
      ],
      "metadata": {
        "id": "jVZYE5GrU33H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LlavaForConditionalGeneration, AutoProcessor\n",
        "import torch\n",
        "\n",
        "model_path = \"chaoyinshe/llava-med-v1.5-mistral-7b-hf\"\n",
        "\n",
        "model = LlavaForConditionalGeneration.from_pretrained(\n",
        "    model_path,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    attn_implementation=\"flash_attention_2\",   # requires FA2\n",
        "    device_map=\"auto\"                          # multi-GPU ready\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "LSteBPc2XqdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "# loading the image i wanna use\n",
        "image_url = \"your_image_url_here\"\n",
        "image = Image.open(requests.get(image_url, stream=True).raw)\n",
        "\n",
        "text_prompt = \"What is the diagnosis in this X-ray image?\"\n",
        "\n",
        "inputs = processor(text=text_prompt, images=image, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "8VNeG4DwX3NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "outputs = model(**inputs)\n",
        "\n",
        "logits_per_image = outputs.logits_per_image\n",
        "logits_per_text = outputs.logits_per_text\n",
        "\n",
        "predicted_class = logits_per_text.argmax().item()\n",
        "print(f\"Predicted class index: {predicted_class}\")"
      ],
      "metadata": {
        "id": "6Js6hOnzX_IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.title(f\"Prediction: {predicted_class}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BxlpEtXZYKcv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}